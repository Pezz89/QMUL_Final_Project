\documentclass[titlepage, 12pt]{scrartcl} \usepackage{enumitem}

\usepackage[british]{babel}
\usepackage[style=apa, backend=biber]{biblatex}
\DeclareLanguageMapping{british}{british-apa}
\usepackage{url}
\usepackage{float}
\usepackage{caption}
%\restylefloat{table}
\usepackage[table]{xcolor}
\usepackage{multirow}
\usepackage{perpage}
\MakePerPage{footnote}
\usepackage{abstract}
\usepackage{graphicx}
\usepackage{setspace}
% Create hyperlinks in bibliography
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{tabulary}

\usepackage[pass]{geometry}
\usepackage{pdflscape}
\usepackage{graphicx}

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{blindtext}
\setkomafont{disposition}{\normalfont\bfseries}

\usepackage{etoolbox}
\graphicspath{{./resources/}}
\addbibresource{~/Documents/library.bib}

% Fix for medeley's rubbish underscore handeling in generated bib files
\DeclareSourcemap{
    \maps{
        \map{ % Replaces '{\_}', '{_}' or '\_' with just '_'
            \step[fieldsource=url,
                  match=\regexp{\{\\\_\}|\{\_\}|\\\_},
                  replace=\regexp{\_}]
        }
        \map{ % Replaces '{'$\sim$'}', '$\sim$' or '{~}' with just '~'
            \step[fieldsource=url,
                  match=\regexp{\{\$\\sim\$\}|\{\~\}|\$\\sim\$},
                  replace=\regexp{\~}]
        }
        \map{ % Replaces '{\_}', '{_}' or '\_' with just '_'
            \step[fieldsource=url,
                  match=\regexp{\{\\\#\}|\{\#\}|\\\#},
                  replace=\regexp{\#}]
        }
    }
}

%\newsavebox{\abstractbox}
%\renewenvironment{abstract}
%  {\begin{lrbox}{0}\begin{minipage}{\textwidth}
%   \begin{center}\normalfont\sectfont\abstractname\end{center}\quotation}
%  {\endquotation\end{minipage}\end{lrbox}%
%   \global\setbox\abstractbox=\box0 }

%\makeatletter
%\expandafter\patchcmd\csname\string\maketitle\endcsname
%  {\vskip\z@\@plus3fill}
%  {\vskip\z@\@plus2fill\box\abstractbox\vskip\z@\@plus1fill}
%  {}{}
%\makeatother

\newcommand{\dtoprule}{\specialrule{1pt}{0pt}{1.4pt}%
            \specialrule{1pt}{0pt}{\belowrulesep}%
            }
\newcommand{\dbottomrule}{\specialrule{1pt}{0pt}{1.4pt}%
            \specialrule{1pt}{0pt}{\belowrulesep}%
            }

\DeclareCiteCommand{\citeyearpar}
    {}
    {\mkbibparens{\bibhyperref{\printdate}}}
    {\multicitedelim}
    {}

% MATLAB Code block stuff...
\usepackage{color}
\usepackage{listings}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}

\lstset{language=Matlab,
   keywords={break,case,catch,continue,else,elseif,end,for,function,
      global,if,otherwise,persistent,return,switch,try,while},
   basicstyle=\ttfamily,
   keywordstyle=\color{blue},
   commentstyle=\color{gray},
   stringstyle=\color{dkgreen},
   numbers=left,
   numberstyle=\tiny\color{gray},
   stepnumber=1,
   numbersep=10pt,
   backgroundcolor=\color{white},
   tabsize=4,
   showspaces=false,
   showstringspaces=false}
\usepackage[shortcuts]{extdash}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
   keywords={},
    numberstyle=\tiny,
    basicstyle=\scriptsize,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2
}
\lstset{style=mystyle}

\begin{document}
\newgeometry{lmargin=1.5cm}
\begin{titlepage}

    \begingroup

    \setlength{\tabcolsep}{1.5cm}

    \begin{tabular}[c]{p{0.30\textwidth} | p{0.4\textwidth}}

    {\vspace{1.2cm} \Large School of Electronic Engineering and Computer Science \par}
    &
    {\vspace{1.2cm} \large Sound and Music Computing \newline Project Report \the\year \par}\\

    & {\vspace{0.5cm} \Large \textbf{Extraction of Audio Features from PCG Signals for the
Classification of Heart Abnormalities} \par}\\

    \vspace{0.4\textheight}
    \includegraphics[width=5cm]{qmul_logo}
    &
    {\vspace{1cm} \large \textbf{Samuel Perry}}\\

    &
    \multicolumn{1}{|r}{August \the\year}

    \end{tabular}

    \endgroup

\end{titlepage}
\restoregeometry

\doublespacing
\begin{abstract}
   Things and stuff and words...
\end{abstract}

\renewcommand{\abstractname}{Acknowledgements}
\begin{abstract}
I'd like to thank anyone and everyone...
\end{abstract}

\tableofcontents
\newpage

\section{Introduction}
Cardiovascular diseases are the most prevalent cause of death in Europe,
accounting for 37.5\% of all deaths in 2013~\parencite{Eurostat2016}.
Traditionally, cardiac auscultation has been performed manually using a standard
stethoscope, with the aim of detecting heart defects aurally. This has been a
fundamental method for detecting heart valve disorders for over a century.
However, auscultation is a skill that requires training and can only usually be
performed by a medial professional, such as a GP. As a result, manual
auscultation is significantly susceptible to human error~\parencite{Hanna2002}.
Automation of this method using technology may be provide a solution, and
recent research has shown promise in this area. A large amount of research has
focused on analysis of Electrocardiogram (ECG) signals.  Although useful for
detecting pathologies, ECG equipment is expensive and requires a trained
professional for use. Therefore it is not currently feasible for developing
countries and rural areas where there may be few physicians available. A
comparatively affordable and non-invasive alternative is the Phonocardiogram
(PCG)~\parencite[p.130]{Reed2004}. Typically recorded using an electronic
stethoscope, a PCG signal is a recording of sound made as the heart contracts,
analogous to the sound heard by physicians when performing cardiac auscultation
manually. Automated auscultation could provide an initial diagnosis for heart
defects without the need for a trained medical professional. This would allow
relatively cheap equipment to analyse a patient's heart sound, and
automatically recommend further inspection based on analysis.  By providing
earlier diagnosis of conditions that may have otherwise been overlooked, this
technology could have a significant impact on reducing mortality rates as a
result of heart conditions.
% TODO: Write brief overview of history of PCG signal analysis
% TODO: Explain fundamental heart sounds

\section{Related Work}
There are currently a wide variety of methods employed for the analysis and
classification of PCG signals. Current methods can typically be divided into 3
areas, each of which are combined to create a full classification system. These
areas are: signal preprocessing, signal segmentation, and feature
extraction/classification. The performance and evaluation of complete systems
are also discussed in section~\ref{Classification}
% TODO: Make flow diagram of 3 stages


\subsection{Signal Preprocessing}
There are a large number of factors that lead to variation in quality of PCG
recordings: stethoscope type, make and model, its microphone/sensors, the
position used to record (i.e.\ lower left sternal border, apex, pulmonic area,
aortic area), built in filters/signal processing used by the stethoscope (i.e.\
noise filters, anti-tremor filters), medication that a patient may be taking,
as well as many other aspects that may influence the recorded
signal~\parencite[p.4]{Pavlopoulos2004}. This presents a significant issue when
attempting to analyse and compare a database of signals, as variations in
recordings and artefacts caused by factors other than heart sounds will most
likely interfere with analysis and comparison methods. To account for this,
pre-processing methods are widely used, aiming to standardize a database. This
is also used as a way to accentuate features of the data that are expected to
be relevant for classification.\\

A common method employed is the use of decimation and a static filter to remove
unwanted spectral content that is most likely noise~\parencite{Liang1997a,
Homsi2016, Springer2016, Gupta2007}. This helps reduce higher frequency noise
such as speech, microphone movement, breething and other interference caused
externally. Signals are commonly downsampled to around 1--4KHz, with
anti-aliasing filter specifications varying across the literature. Generally,
highpass chebychev or butterworth filters are favoured with cutoff frequencies
ranging from 400--750Hz.\\

In addition, many methods decompose the filtered signal using wavelet based
methods, such as the discrete wavelet transform (DWT)~\parencite{Liang1997a,
Pavlopoulos2004}, continuous wavelet transform (CWT)~\parencite{Langley2016} or
wavelet package decomposition (WPD)~\parencite{Liang1998}, are commonly used to
separate components of a signal based on their spectral content.
Wavelet transforms are popular as, unlike Fourier transforms, they are well
localized in both the time and frequency domain. This allows for the analysis
of PCG signals across multiple frequency bands whilst maintaining transient
temporal events in the resulting decomposition~\parencite[p.93]{Ari2008}.
This may be used for analysis of transient events such as murmurs, that may
consist of higher frequency components than normal heart sounds.

\subsection{Signal Segmentation}\label{Segmentation}
Algorithms for the segmentation of PCG data aim to  extract the structure of
the signal over time. This is a key stage in the analysis of PCG signals, as the
structure and relationships between the fundamental heart sounds (FHSs) form
the basis for much of further analysis performed on PCG data.\\

% TODO: insert segmented graph of PCG cycle

A number of methods exist for the extraction of FHSs. Traditional methods rely
on direct extraction of peaks from amplitude envelopes in the time domain to
determine the structure of a signal.  These methods perform various
processing/transformations in order to accentuate the transient events with the
intention of isolating them.\\
Early work in this area by Liang et.\ al described a method using the popular
Shannon energy envelope, achieving good accuracy across 37 recordings of
children~\parencite{Liang1997b}. The algorithm aimed to segment the data by
first extracting the envelope, then applying adaptive rule based thresholds, to
determine peaks corresponding to segmentation points. When comparing results to
hand annotated ground truth data, the system achieved a reported accuracy score
of 84\%. However, due to the small sample size, and potential lack of noise in
the database used, this may not translate to a larger database recorded in
sub-optimal conditions.\\
More recent methods used spectral representations to assist in the splitting of
the FHSs, in particular using wavelet decomposition. These methods tend to
perform more robustly on signals of varying conditions.\\
Building on previous work, Liang et.\ al presented an improved method, using the
discrete wavelet transform to decompose and reconstruct the signal into 7
distinct frequency bands~\parencite{Liang1997a}. Applying a similar method
of envelope extraction and peak picking to each frequency band, the best
estimate of all frequency bands is then chosen as the final result. Criterion
for this choice is based on the number of S1s and S2s detected, and the number
of artefacts discarded for each frequency band. This method achieved an
improved accuracy of 93\% across a larger database of 77 recordings. This
suggests that the algorithm is as robust if not more so than previous work by
Liang et\ al.\\

Vepa et.\ al proposed a wavelet decomposition based method that uses a
combination of simplicity and envelope features~\parencite{Vepa2008}. This
approach attempts to improve robustness when analysing signals of varying
quality by using multiple complimentary features. This allows the method to base
decisions on a variety of statistical properties. Evaluating the algorithm on a
collection of 160 heart cycles from a variety of sources, a reported accuracy
of 84\% was achieved.\\

More recently, a variety of machine learning methods have been implemented with reasonable
success. Gupta et.\ al presented a method that applies $k$-means clustering to
replace standard threshold based methods for determining peak classification in
a standard envelope based segmentation algorithm~\parencite{Gupta2007}. This achieved a reported
accuracy of 90.29\%. Due to the envelope based method for feature extraction,
this method is still suceptible to noise and artefacts that occur within the
frequency bands of the heart sounds.\\

Sepehri et.\ al proposed a method that combines neural networks with Power
Spectral Density (PSD) estimates~\parencite{Sepehri2010}.  By exploiting the
periodic nature of S1 and S2 heart sounds, combined with their narrow frequency
range, a neural network is trained to separate these sounds from other events,
such as noise and murmurs. This method achieved a reported 93.6\% accuracy on a
significantly larger database than previous methods detailed.\\

Most significant success in segmentation algorithms has been observed through use
of probabilistic models such as Hidden Markov Models (HMMs). Early research
using these models by Ricke et.\ al utilised embedded HMMs to model the 4
states of the PCG and their transitions~\parencite{Ricke2005}. MFCCs and
Shannon Energy were used as feature vectors for the models. Results of
98\% accuracy were reported, although this was tested on only a small database
of signals.\\
Gill et.\ al achieved similar results, most notably with specific consideration
for the duration of each state in the HMM~\parencite{Gill2005}. This is
handled through the extraction of 6 duration features based primarily on peaks.
These features form vectors for training the HMM. Results of 98.6\%
sensitivity, 96.9\% positive predictivity for S1 sounds and 98.3\% sensitivity,
96.5\% positive predictivity for S2 sounds is reported.
The issue of state duration was further addressed by Schmidt et.\ al through use
of a duration-dependent hidden Markov (DHMM)~\parencite{Schmidt2015}. The
DHMM is a modified HMM that considers the duration of the current state when
calculating the probability of transition to another state. This modification
scored a reported sensitivity of 98.8\% and a positive predictivity of
98.6\%.\\
Building on previous work using HMMs, Springer et.\ al presented a segmentation
algorithm by using hidden semi-markov models (HSMMs) in combination with
logistic regression~\parencite{Springer2016}. Use of Hidden semi markov model
allows for a priori information on the duration of the current state to be used
in probability calculation of the subsequent state. In this case, the knowlege
that there is an upper and lower limit on the duration of each component is
used in calculation of transition probabilities.  A modified viterbi algorithm
is then used to calculate the most likely set of transitions based on observed
features. Logistic regression is used to improve discrimination between state
features when compared to discriminatory methods used by previous work.
Performance was evaluated on a significantly larger database than previous
methods and achieved a reported accuracy of $95.63\% \pm 0.85\%$. Due to it's
rigorous evaluation and high accuracy, this method is currently considered the
state-of-the-art for PCG signal segmentation.\\

Table~\ref{SegmentationTable} provides a brief overview of significant research
into PCG segmentation. For a more complete summary of the current state of PCG
segmentation, please refer to Liu et.\ al~\parencite{Liu2016}

\newgeometry{margin=1cm} % modify this if you need even more space
\begin{landscape}
\begin{table}[htbp]
    \captionof{table}{Summary of Segmentation Algorithms} \label{SegmentationTable}
\scriptsize
%\centering
\rowcolors{1}{gray!15}{white}
\doublespacing
\begin{tabulary}{\linewidth}{LLLLL}
\dtoprule
Author                 & Method                                                                                         & databases                                                                                       & \mbox{Reported} Results         & Notes                                                                                            \\ \bottomrule
Springer et.\ al \citeyearpar{Springer2016} & HSMM, Logistic regression                                                                       & 10,172s of recordings from 112 patients. 12,181 first and 11,627 second heart sounds. & $95.63\pm0.85\%$                             & Supervised algorithm.                                                                                                                                                            \\
Huiying et.\ al \citeyearpar{Liang1997b} & Normalised average Shannon energy envelope, peak picking                                        & 37 recordings, 14 pathological murmurs and 23 physiological murmurs. 515 cycles       & $91.03\%\;Ac$                                          & Unsupervised Algorithm.  database consists entirely of child recording. Optimized on full database                                                                                 \\
Vepa et.\ al \citeyearpar{Vepa2008}     & Wavelet decomposition, energy and simplicity measurement                                       & 160 heart cycles collected from a variety of sources (training CDs, web resources)    & $84\%\;Ac$                                             & Unsupervised Algorithm, Optimized on full database                                                                                                                                \\
Sun et.\ al \citeyearpar{Sun2014}             & Viola integral envelope extraction, short-time modified Hilbert transform, peak picking        & 6949s of recordings, from 121 patients                                                & $97.37\%\;Ac$                                          & Supervised algorithm. Tolerance for segmentation accuracy not specified                                                                                                          \\
Sepehri et.\ al \citeyearpar{Sepehri2010}        & Spectral density estimation, auto-regressive parameters, multi-layer perceptron neural network & 120 recording, from 60 patients                                                       & $93.6\%\;Ac$                                           & Supervised algorithm                                                                                                                                                             \\
Ricke et.\ al \citeyearpar{Ricke2005}    & Shannon energy (and related features), HMM                                                     & 9 recordings, from 9 patients                                                         & $98\%\;Ac$                                             & Supervised algorithm                                                                                                                                                             \\
Schmidt et.\ al \citeyearpar{Schmidt2015}  & DHMM, Auto-correlation duration features, Homomorphic envelogram                               & 113 recordings, from 113 patients. 8s per recording. 15 abnormal recordings           & $98.8\;Se,\;98.6\;P_+$ on test set                         & All data recorded ``lateral to the sternum in the fourth intercostal space on the left side''. Mix of noisy and clean recordings. 40 recording used for training, 73 for testing \\
Gill et.\ al \citeyearpar{Gill2005}         & Homomorphic envelogram, Embedded HMMs                                                          & 44 recording, 17 subjects. 30-60s per recording                                       & $98.6\%\;Ac, 96.9\;P_+$ for S1. $98.3\;Ac,\;96.5\;P_+$ for S2 & Recording taken in sub-optimal environments (noisy hospitals, offices etc...)                                                                                                    \\
Gupta et.\ al \citeyearpar{Gupta2007}    & Homomorphic filtering, $k$-means clustering                                                       & 41 patients, 340 heart cycles. 110 normal,  124 systolic murmur, 106 diastolic murmur & $90.29\%\;Ac$                                          & Unsupervised Algorithm.                                                                                                                                                          \\ \hline
\dbottomrule\\
% TODO: Add footnote explanation for Ac = Accuracy
% TODO: Add citeyearpar references to authors
\end{tabulary}
\end{table}
\end{landscape}
\restoregeometry


\doublespacing

\subsection{Feature extraction/Classification models}\label{Classification}

A wide variety of methods exist for the extraction of statistical features and
classification of PCG data. Most notably, the recent Physionet/Computing in
Cardiology (CinC) Challenge 2016 has prompted the development of a range of
methods that have improved the quality of abnormality classification in noisy
signals.  The challenge was assembled to provide researchers with a large
database of normal/pathological PCG signals of varying quality. This enabled
the development of algorithms that could be evaluated on a significant
database, in order to determine performance across a range of conditions/signal
qualities~\parencite{Clifford2016}. This section first details significant work
produced prior to the challenge, then highlights key works produced for the
challenge to outline the breadth of methods for robust heart sound analysis.

\subsubsection{Work prior to the Physionet challenge}
Work prior to the Physionet challenge was conducted predominantly with the aim
of classifying specific heart conditions. Until recently, little research had
been produced with regards to general abnormality detection, with many projects
choosing to focus on specific conditions such as murmurs, atrial fibrillation,
flutter, and heart valve disease. This section outlines some key research
into these areas, alongside initial research into general abnormality
detection.\\

Reed et.\ al implemented a simple general classification algorithm using artificial
neural networks (ANNs) and wavelet decomposition~\parencite{Reed2004}. As
initial work into this field, preprocessing such as segmentation is not
performed and features remain relatively simple when compared to more recent
methods. Also, due to the comparitively small sample size used for training (1
patient per abnormality, 4 cycles per patient), a reported accuracy of 100\%
would likely generalise poorly. This does however, serve as an early example of
limited success in general heart sound classification.\\

Maglogiannis et.\ al presented a classifier for discrimination of heart valve
disease from regular heart sounds using an SVM (Support Vector Machine)
classifier~\parencite{Maglogiannis2009}.  Roughly 100 features were extracted
from the signal, based on direct analysis of each heart cycle component (S1,
Systole, S2, Diastole) and the average shannon energy envelope of these
components.  A database of 198 heart sounds was curated for the project,
acquired from 8 sources, such as medical CDs and pre-existing databases.  An
accuracy of 91.43\% was reported using 10-fold stratified cross-validation.  In
addition, the project aimed to classify individual abnormalities in a 3 step
process, by distinguishing between systolic or diastolic murmurs, and then
distinguishing between aortic or mitral diseases. The classifier achieved
accuracy between 90-97\% for these classifications. This approach demonstrates
the potential for a system to accurately distinguish between normal and
abnormal heart sounds in a generalisable way, given carefully selected
features.\\

Ari et.\ al also proposed an SVM based method for abnormality
classification~\parencite{Ari2010}. A modified Least-squares SVM (LSSVM) is
used in order to improve separability between normal and abnormal datapoints
during training. 32 wavelet based features from previous literature are used as
feature vectors for a modified LSSVM, un-modified LSSVM and a standard SVM.
Comparison of the system shows that the proposed technique performs
significantly better on all test sets with an accuracy of between 86\% and
100\%, dependent on database. This research highlights the importance of
choosing an appropriate classification method for achieving accurate results.\\

Quiceno-Manrique et.\ al demonstrate the use of various time frequency
representations (TFR) such as short-time fourier transform, wavelet transforms,
Wigner-Ville distribution etc\ldots, with a $k$-nearest neighbour classifier
(k-NN) for systolic murmur detection~\parencite{Quiceno-Manrique2010a}. This
work highlights the effectiveness of alternative TFRs to traditional fourier
methods. This method also employs Principle Component Analysis (PCA) for the
mapping of a high dimensional feature space to a lower dimension, for the
benefit of computational performance. Features were evaluated using a database
of of 22 patients, 6 of which were labeled as having a systolic murmur. The
highest reported accuracy was achieved using MFCCs as the primary feature
vector achieving a 98\% accuracy on 10-fold cross validation.\\

Schmidt et.\ al aimed to find features that could be used for classification of
coronary artery disease through detection of small
murmurs~\parencite{Schmidt2015}. A large number of features are
calculated to provide vectors for classification; Parametric spectral features
such as ARMA are used, alongside instantaneous frequency and octave power
measurements. Complexity features such as sample entropy and simplicity are
also calculated in an attempt to exploit the likely stochastic nature of
murmurs, when compared to normal heart sounds.  Given the large number of
features calculated, PCA is used to retain only the most relevant information.
Quadratic discriminant analysis (QDA) is then used as a classifier to provide a
final accuracy score of 73\%.\\

An overview of significant research prior to the Physionet challenge is
provided in table~\ref{SumPrior}. It is also noted that none of the databases
used for prior research are publicly available.


\newgeometry{margin=1cm} % modify this if you need even more space
\begin{landscape}
\begin{table}[htbp]
    \captionof{table}{Summary of research prior to the Physionet Challenge 2016}\label{PriorWorkTable}
\scriptsize
%\centering
\rowcolors{1}{gray!15}{white}
\label{SumPrior}
\doublespacing
\begin{tabulary}{\linewidth}{LLLLLL}
\dtoprule
Author                   & Pre-processing/segmentation                                                                                                               & Features                                                                                                        & Classification Method & Database                                                                                                                 & Reported Accuracy                                  \\ \hline
Maglogiannis et.~al \citeyearpar{Maglogiannis2009}     & Wavelet decomposition, Shannon energy peak picking                                                                                        & Features derived from wavelet decomposition and PCG segmentations                                               & SVM                   & 198 recordings, 38 normal, 41 AS systolic murmur, 43 MR systolic murmur, 38 AR diastolic murmur, 38 MS diastolic murmur & $91.43\%\;Ac$                                      \\
Ari et.~al \citeyearpar{Ari2010}              & Amplitude envelope peak picking~\parencite{Ari2007}                                                                                       & Wavelet based features                                                                                          & LSSVM                 & 64 patients, 64 recordings, 512 cycles                                                                                  & $88.750-100\%\;Ac$ (dependant on abnormality type) \\
Quiceno-Manrique et.~al \citeyearpar{Quiceno-Manrique2010a}& Downsampled to 4KHz, Normalised to maximum of signal, ECG assisted QRS complex detection algorithm used for segmentation                  & Spectral features derived from STFT, Wavelet decomposition and quadratic energy distributions                   & $k$-NN                & 22 patients, 16 normal, 6 abnormal, 8 recordings (12s) per patient                                                      & $98\%\;Ac$                                         \\
Schmidt et.~al \citeyearpar{Schmidt2015}          & Signal filtered into frequency bands, Segmented by HMM based method+hand corrected, removal of high variance sub-segments to remove noise & Parametric spectral features (AR, ARMA and Music), Instantaneous frequency and amplitude, Power in octave bands & QDA                   & 435 Recordings, 133 patients, 70 normal, 63 abnormal                                                                    & $73\%\;Ac$                                         \\
Reed et.~al \citeyearpar{Reed2004}             & ---                                                                                                                                       & Wavelet decomposition coefficients, Manual feature reduction                                                    & ANN                   & 5 patients, 4 cycles per patient                                                                                        & $100\%\;Ac$                                        \\
\dbottomrule\\
% TODO: Add footnote explanation for Ac = Accuracy
% TODO: Add citeyearpar references to authors
\end{tabulary}
\end{table}
\end{landscape}
\restoregeometry

\subsubsection{Physionet challenge entries}
\doublespacing
The 2016 Physionet/CinC Challenge aimed to encourage development of heart
abnormality detection algorithms by providing a large open database of PCG
signal recordings, sourced from a variety of both clinical and non-clinical
environments. (Further details on the database can be found in
section~\ref{Database}. The complete specification is presented by Liu et.\
al~\parencite{Liu2016}). In addition, participants were provided with a
state-of-the-art heart sound segmentation algorithm, as proposed by Springer
et.\ al in Section~\ref{Segmentation}. Participants were then tasked with the
creation of a classification algorithm that could robustly discriminate between
healthy and unhealthy heart sound samples. The challenge recieved 348 entries
in total, each of which was scored on a hidden test database
using a Modified accuracy measure ($MAcc$) as defined by Clifford et.
al~\parencite{Clifford2016}:
\begin{table}[htbp]
\centering
\caption{Output Classification}
\label{OutputClassification}
\doublespacing
\begin{tabular}{llccc}
\hline
                              &                 & \multicolumn{3}{c}{Algorithm's Output}                                                    \\ \hline
                              &                 & \multicolumn{1}{l}{Normal} & \multicolumn{1}{l}{Uncertain} & \multicolumn{1}{l}{Abnormal} \\
\multirow{4}{*}{Ground Truth} & Normal, clean   & $Nn_1$                     & $Nq_1$                        & $Na_1$                       \\
                              & Normal, noisy   & $Nn_2$                     & $Nq_2$                        & $Na_2$                       \\
                              & Abnormal, clean & $An_1$                     & $Aq_1$                        & $Aa_1$                       \\
                              & Abnormal, noisy & $An_2$                     & $Aq_2$                        & $Aa_2$                       \\ \hline
\end{tabular}
\end{table}

\doublespacing

Weights are calculated as:
\begin{table}[H]
\centering
\doublespacing
\begin{tabular}{ll}
$Wa_1 = \frac{\text{Clean abnormal recordings}}{\text{Total abnormal recordings}}$ & $Wa_2 = \frac{\text{Noisy abnormal recordings}}{\text{Total abnormal recordings}}$ \\
$Wn_1 = \frac{\text{Clean normal recordings}}{\text{Total normal recordings}}$     & $Wn_2 = \frac{\text{Noisy normal recordings}}{\text{Total normal recordings}}$
\end{tabular}
\end{table}

Modified sensitivity ($Se$), specificity ($Sp$) and overall accuracy ($MAcc$) are then calculated as:

\begin{align*}
    &Se=Wa_1\frac{Aa_1}{Aa_1+Aq_1+An_1}+Wa_2\frac{Aa_2+Aq_2}{Aa_2+Aq_2+An_2} \\
    &Sp=Wn_1\frac{Nn_1}{Na_1+Nq_1+Nn_1}+Wn_2\frac{Nn_2+Nq_2}{Na_2+Nq_2+Nn_2} \\
    &MAcc=\frac{Se+Sp}{2}
\end{align*}

This section summarises some of the key works presented for the challenge,
including some of the most accurate models, and a baseline classifier
provided to participants as a starting point.\\

A simple baseline classifier was provided to participants in order to
demonstrate the basic structure of systems expected for
entries~\parencite{Liu2016}. The classifier extracted a selection of 20 basic
features, primarily focused on relative timings and amplitudes of heart sounds.
A binary logistic regression model is chosen for classification. From the 20
extracted features, 13 were selected based on their statistical significance,
measured using foreward liklihood ratio selection. The system achieved a
reported score of 66\% on the test set, giving a baseline score for participants
to build on.  In addition, the system was trained using leave-one-out cross
validation. By removing a single training database on each fold, the
generalisation of the algorithm trained on all other databases could then be
evaluated. Results showed that performance decreased significantly when
training via this method, giving an average accuracy of 59\%, with training
database $b$ scoring as low as 47\%.  This could suggest that individual
databases in the database are not sufficiently represented by other databases,
or that features do not model abnormalities sufficiently.\\

Homsi et.\ al proposed a system that utilised 131 time domain, STFT based and
wavelet based features, combined with nested ensemble classifiers to produce an
accuracy score of 84.48\%~\parencite{Homsi2017}. This algorithm combines many
commonly used features in previous PCG related literature such as wavelet
decomposition based features, MFCCs and Shannon Energy. The system also uses a
total of 40 classifiers, 20 for signals labeled to be `standard' and 20 for
thos labeled as `atypical'. A mixture of Random Forrest, LogitBoost and
Cost-Sensitive Classifiers (CSC) are used to classify signals in parallel. Final
results are combined using a rule based decision, designed through manual
experimentation.\\
% TODO: Read into accuracy results for this method more closely

Potes et.\ al present a similar approach to that of Homsi et.\
al~\parencite{Potes2016}. 124 similar TFR features are extracted
and used as vectors for an AdaBoost classifier. This was combined with a deep
learning approach using a Convolutional Neural Network (CNN) classifier. The
signal was decomposed into 4 frequency bands and segmented, to provide input to
the CNN. Results from both AdaBoost and CNN classifiers were then combined
using a set descision rule.  This method produced the highest score on the test
set for the challenge at 86.02\%.\\

Zabihi et.\ al take an alternative approach by choosing not to segment PCG data
in the pre-processing stage~\parencite{Zabihi2016}. This is with the intention of reducing
computational complexity of the resulting algorithm. In addition, the proposed
method utilizes a wrapper sequential forward
feature selection (SFS) and Linear Predictive Coefficients (LPC) for the reduction
of features used for classification. This benefits the system by removing correlated and irrelevant
features, Thus reducing computational complexity and removing irellevant noise
from feature vectors prior to training.
Final classifications are determined through cascaded ensembles of ANNs. The
signal is first classified as either of high or low sound quality, and then as
normal or abnormal. The system achieved a final score of 85.9\% on the hidden
test set.\\

Plesinger et.\ al opted to develop a new for of machine learning algorithm
based on probability assesment~\parencite{Plesinger2017}. In this method,
features are mapped to histograms and thought of as probability distributions.
weights are applied based on number of occurences of each feature, and a
probability function is generated. This can then be used to calculate the
estimated classification of a new data point. From the 228 extracted features,
53 features were then selected based on calculated sensitivity and specificity
scores using generated histograms. This allowed for the training scores to be
automatically optimized by the algorithm.\\

Kay et.\ al present a method using ANNs, a wide variety of features and PCA for
feature reduction. The algorithm scores well on the test set. However, this
work is most noteable for it's rigurous evaluation by authors, using leave on
out cross validation for a clearer understanding of  the generalisation of the
algorithm, as well as highlighting issues with the underlying database that are
discussed in Section~\ref{Database}


\newgeometry{margin=1cm} % modify this if you need even more space
\begin{landscape}
\begin{table}[H]
    \captionof{table}{Summary of top 10 Physionet Challenge 2016 entries}
    \label{PhysionetTable}
\scriptsize
%\centering
\rowcolors{1}{gray!15}{white}
\doublespacing
\begin{tabulary}{\linewidth}{CCCCC}
\dtoprule
Author                                           & Features                                                                        & Classification Method                                    & Reported Scores                                                                                      & Challenge Score \\ \midrule
Potes et.~al \citeyearpar{Potes2016}             & 124 TFR features                                                                & Combined AdaBoost/ANN                                    & In-house test set accuracy: AdaBoost-abstain: 79\%, CNN: 82\%, Combined classifiers: 85\%            & 86.02\%         \\
Zabihi et.~al \citeyearpar{Zabihi2016}           & 40 temporal, spectral and TFR features, reduced using SFS and LPC               & 2 ensembles of neural networks                           & Training accuracy: Maximum of 91.50\%                                                                & 85.90\%         \\
Kay et.~al \citeyearpar{Kay2017}                 & CWT, MFCCs, complexity measures, Inter-beat features, PCA                       & ANNs                                                     & A range of cross validation based tests were used to analyse performance. See paper for full details & 85.20\%         \\
Bobillo \citeyearpar{Bobillo2016}                & MFCCs and WPD, reduced using tensor decomposition                               & $k$-NN                                                   & A range of cross validation based tests were used to analyse performance. See paper for full details & 84.54\%         \\
Homsi et.~al \citeyearpar{Homsi2017}             & 131 time domain, STFT based andwavelet based features                           & Combined ensembles of LogitBoost, Random Forrest and CSC & Training accuracy 87.7\%, In-house test accuracy: 93.24\%                                            & 84.48\%         \\
Maknickas et.~al \citeyearpar{Maknikas2017}      & MFCCs, reduced by Karhunenâ€“Loeve transform                                      & Deep Neural Network                                      & Training accuracy 99.7\%, Validation accuracy 95.2\%                                                 & 84.15\%         \\
Plesinger et.~al \citeyearpar{Plesinger2017}     & Statistical and symettry properties of amplitude envelopes for S1 and S2 sounds & Custom probability assesment machine learning algorithm  & Training accuracy 90.3\%                                                                             & 84.11\%         \\
Rubin et.~al \citeyearpar{Rubin2016}             & MFCCs                                                                           & Convolutional neural networks                            & --                                                                                                   & 83.99\%         \\
Jiayu (paper not submitted)                      & --                                                                              & --                                                       & --                                                                                                   & 82.82\%         \\
Abdollahpur et.~al \citeyearpar{Abdolahpur2017} & time, TFR and perceptual features, reduced using Fisher's discriminant analysis & Combined ANNs                                            & Training accuracy: 91.6\%, 87\%, 84.55\% (prior to ANN combination method)                           & 82.63\%\\
\dbottomrule\\
% TODO: Add footnote explanation for Ac = Accuracy

\end{tabulary}
\end{table}
\end{landscape}
\restoregeometry
% TODO: Summary of the way projects were evaluated in general, and what could be improved
\doublespacing
\section{Database}\label{Database}
%TODO: Briefly describe what is needed from a database for this project
A database representative of real-world PCG signals was needed to train models
and evaluate the proposed method effectively.  A number of criteria were
identified as necessary for the success of the proposed project:
\begin{itemize}
    \item It was required that the database contained sufficient PCG data, so
        that a model trained to discriminate between said signals would
        in theory generalise to new PCG data.
    \item A theme present in almost all previous research is that of noise. As
        real-world classification would likely be performed in sub-optimal
        conditions the database should contain a mixture of clean and noisy
        signals that represent a variety of real world situation. If this is
        not possible, noise could potentially be added to clean signals to
        simulate this.
    \item As this project aims to provide a general abnormality detection
        algorithm, it must be able to differentiate healthy signals from a
        variety of individual pathologies. This should be reflected in the
        database through inclusion of a variety of signals representing
        different pathological heart conditions.
    \item Reliably labeled data is key for generating a reliable model
        (paticularly when using machine learning methods, as in the proposed
        project). Labels should ideally be verified by a trained professional.
\end{itemize}
\noindent
Two viable options were then considered based on the above criteria:
\begin{enumerate}
    \item The Physionet challenge database
    \item Generation of a synthetic dataset via methods such as that proposed
    by Almasi et.\ al~\parencite{Almasi2011}
\end{enumerate}

Generation of synthetic data was considered as few well formed alternative
databases exist other than the Physionet challenge data. The database curated
for the Physionet challenge was selected for this project, as it fulfilled the
criteria sufficiently and posed less of a risk in terms of signal quality, due
to all signals being produced in real-world environments.  However, synthesis
of PCG data remains an interesting possibility for improving evaluation of
classification systems and is discussed in Section~\ref{FurtherWork}.

\subsection{Database Summary}
The selected database is significantly larger and contains a wider variety of
signal conditions than any database used for previous research (as detailed in
table~\ref{PriorWorkTable}). It is released as an open-source resource and is
documented in significant detail by Liu et.\ al~\parencite{Liu2016}. The lack
of any alternative databases, comparable in size or variety of content, perhaps
makes this resource the current standard for PCG analysis projects. In
addition, by replicating the conditions of the Physionet challenge, results can
also be directly compared with those of the challenge participant's, with the
aim of understanding how the proposed algorithm compares to the current state
of PCG analysis.

\begin{itemize}
    \item The database consists of 6 sub-databases, labeled $a$ to $f$.
    \item These sub-databases have been sourced from a variety of professionals,
        over the course of a decade.
    \item A total of 3,126 recordings are included, created using varying equipment.
    \item 2575 recordings are labeled as normal, 665 are labeled as abnormal.
    \item All samples have been resampled to 2KHz
    \item Samples were recorded in a range of enviroments, both clinical and
        non-clinical.
    \item Many recordings are corrupted with environmental noise, such as
        microphone friction, breathing, talking etc\ldots
    \item Sections of silence are present in some recordings, most
        significantly in database $e$
\end{itemize}

\subsection{Considerations}\label{DBCons}
There are a number of issues with the acquired database that have been
highlighted, both through previous literature and through development of the
project. These have been considered throughout development and evaluation of
the project.\\
A significant issue highlighted by Liu et.\ al is the large number of normal
recordings compared to pathological recordings. This creates a clear class
imbalance issue that can result in over-inflated classification
results. This is considered in
Section~\ref{Resample}.\\
Another key issue is the difference between the databases used by participants of the
Physionet challenge, and the available data that was acquired for this project.
% TODO: Update to reflect use of quality labels that have now been found
For unknown reasons, information such as patient labels and signal quality
labels used for training many of the challenge participant's
models have not been made available publicly and so could not be
used in this project. A solution to the lack of signal quality labels is
proposed in Section~\ref{Quality}.\\
The lack of access to the hidden test set used for evaluating challenge entries
also had a significant impact on evaluation. An alternative method for
evaluating using only the data provided has been proposed in
Section~\ref{Eval}.\\
Finally, an issue is highlighted by Bobillo with regards to database
$e$~\parencite{Bobillo2016}. The recording of normal and pathological signals using
separate devices is likely to cause issues and is discussed in
Section~\ref{Eval}

\section{Design}
This project aims to provide robust heart abnormality detection for PCG
signals, such that use of the system could reliably recommend further medical
attention when neccesary. It is clear from previous research that machine
learning methods for classification have shown the most promise in this area,
and that ensemble methods have been largely sucesful in improving
classification accuracy of base classifiers~\parencite{Homsi2017, Potes2016}.
However, one such method that has recently shown significant success and is not
present in recent literature is the stacking
meta-classifier~\parencite[p.498]{Tobergte2013a}. The presented system was
therefore designed to explore the potential for this classification method in
the context of PCG signal classification. This section details the four key
components developed to form the final system: signal preprocessing
(Section~\ref{preprocessing}), audio feature extraction (Section~\ref{featEx}),
classification (Section~\ref{class}) and optimisation (Section~\ref{optimise}).

% TODO: Create flow diagram Preprocessing -> Feature extraction ->
% Model optimisation -> Performance evaluation

\subsection{Preprocessing}\label{preprocessing}
It quickly became apparent that, due to significant variations in the available
data (as a result of noise, variations in recording equipment etc...), that the
effective preprocessing of such data would be a critical factor when designing
the system. This section details the most significant preprocessing steps taken
in order to both minimize noise, and extract the basic structure of the signal.

\subsubsection{Downsampling}
A common method employed to simultaneously reduce computation time and remove
extraneous information is to decimate the input signal by an integer factor.
According to shannon sampling theorem, a digital signal can only represent
frequency content up to half the sample rate of the signal (the nyquist
rate)~\parencite[p.140]{Kadis1999}
Therefore, by removing every $n$th sample, high frequency content can be
removed whilst lowering the number of samples that must be processed in
subsequent operations. An anti-aliasing filter must also be applied to the
signal in order to filter harmonic distortion generated by the process.
As it is commonly stated in the literature that little relevant information in
PCG signal is found above 400Hz, all signals were resampled to 1KHz giving a
500Hz cutoff frequency, using a 8th order zero-phase Chebyshev type I filter.

\subsubsection{Resampling dataset}\label{Resample}
A common issue with data collected from the real world is the imbalance of
classes in data. As noted by Liu et. al~\parencite{Liu2016}, this is the case
with the available dataset, as there are less pathological signals than healthy
signals.  This presents an issue with classification tasks, as imbalance can
have a negative impact on classification of the minor
class~\parencite{Longadge2013}. In this context, this would potentially have a
significant impact on classification accuracy for abnormal samples, so must be
handled appropriately.
Two common methods for approaching this are bootstrap resampling (sampling with
replacement) and jacknife resampling (sampling without replacement). Both
methods have been used accross previous literature, however, jacknife
resampling was chosen for this project. This was to avoid overfitting the
classification model as a result of
the multiple identical samples generated using the bootstrap method. It is
noted that this method does result in a significant loss of information,
reducing the dataset size from 3240 samples to 944.

\subsubsection{Signal Segmentation}
%TODO: Generate segmentation plot
With one notable exception~\parencite{Langley2016}, previous classification
algorithms rely heavily on the ability to segment signals into the four
fundamental heart sounds. This is a key prerequisite to the extraction of
relevant features. The defining of signal structure allows for the
relationships between it's components to be analysed as described in
Section~\ref{featEx}. To faciliatate the development of robust agorithms for
the Physionet challenge, participants were provided with an implementation of
Springer's HSMM based segmentation algorithm. As the highest scoring algorithm
in the literature, it was clearly the most suitable algorithm to use for the
proposed system. In addition to the high accuracy of segmentation, the wide
adoption of this algorithm is beneficial for comparison with other algorithms
submitted to the challenge. Results produced by the proposed system will
generally not be coloured by the differences in quality of segmentation
algorithms, allowing for more direct comparison of classification methods.
However, it is noted that despite the high performance of the algorithm, errors
in segmentation will still occur that may have a negative impact on feature
quality. As methods proposed by previous literature such as hand correction by
a professional~\parencite[p.2203]{Liu2016} are not feasible in this context,
and considering the low number of erroneous results produced by the
algorithm~\parencite[p.2]{Goda2016} it was decided that these errors would not
pose a significant problem.


\subsection{Feature Extraction}\label{featEx}
The extraction of feature vectors from data is a fundamental component of most
machine learning based systems. The aim is to construct meaningful
representations of the data that emphasize information relevant to the
classification problem. In the proposed project, 188 features were extracted
from the data, procuring feature extraction techniques from a wide range of
previous literature, as well as using novel perceptual features commonly found
in audio/music analysis (See Sections~\ref{FFT} and~\ref{Time}).
There are also potential issues that can occur when using large sets of
features for training. The method proposed for addressing these issues is
discussed in section~\ref{SFS}. This section provides a summary of the main
feature categories. Please refer to appendix~\ref{appendixA} for a full
breakdown of all features.

\subsubsection{Time-domain features}\label{Time}
A range of features were generated, based directly on the time series data.
Features such as:
\begin{itemize}
    \item Average and standard-deviation of segment intervals, for all heart
        sounds and complete heart cycles
    \item Ratio of systolic and diastolic period to total heart cycle period
    \item A range of statistical features such as entropy, skewness and variance for
        each heart sound
    \item A selection of envelope based features for each heart sound
\end{itemize}

18 feature provided by the Physionet challenge focused on timings between
segments of the heart cycles. It was thought that these features would be
useful in capturing irregularities caused by conditions such as arrhythmias,
atrial septal defect and other conditions that are likely to affect relative
timing of heart sounds~\parencite[p.29, 64, 127]{Brown2008}.\\
Many conditions that can be detected by traditional auscultation are
characterised by an increase in loudness of the S1 and/or S2 heart
sounds~\parencite{Brown2008}. This suggests that features relating to human
perception of loudness may aid in the detection of such conditions.  Simple
envelope based features such as RMS, peak loudness and the Shannon energy
envelope (Equation~\ref{ShanEQ}, popular in previous literature, were extracted
for this reason~\parencite[p.73-77]{Lerch2012}. In addition, statistical
features such as sample entropy and skewness (Equation ~\ref{SkewEQ}) were used
to evaluate the distribution of samples for each heart sound, these were
selected to provide a representation of the temporal ``shape'' of each sound.

\begin{equation}\label{ShanEQ}
    SE = \frac{-1}{N}\sum\limits_{n=0}^N x(n)^2\cdot \log{x(n)^2}
\end{equation}
\begin{equation}\label{SkewEQ}
    S=\frac{E(x-\mu)^3}{\sigma^3}
\end{equation}
Where:\\
$x(n)$ is the input signal\\
$E(t)$ is the expected value\\
$\mu$ is the mean of the signal\\
$\sigma^2$ is the variance of the signal

\subsubsection{FFT-based features}\label{FFT}
It was recognised that a time domain representation alone was unlikely to
provide a sufficient representation for discerning a wide variety of
conditions. Using a time-frequency representation to characterise the spectral
components of the signal has proven effective in the majority of literature.
The classic method for producing a spectral representation of a signal is the
Fourier transform (as defined in Equation~\ref{FFTEQ}) over a sliding window of size
$N$. By decomposing the signal into a series of sine and cosine
waves, a representation of the signal across a range of frequency bands is
produced. This can be used for further analysis of heart sounds
based on their spectral characteristics.
\begin{equation}\label{FFTEQ}
X(k)=\sum\limits_{n=0}^{N}x(n)e^{\frac{-j2\pi kn}{N}}
\end{equation}
Where $x(n)$ is the input signal\\
Features generated using this representation would, in theory, be useful for
identifying conditions that reside in specific frequency bands, such as
murmurs, for example~\parencite{Sepehri2010}.\\

An example of such features are Mel-Frequency Cepstrum Coefficients (MFCCs).
Popular in speech processing, MFCCs provide a compact representation of a
signal's spectral shape. MFCCs are calculated by first applying $N$ (a
user-defined parameter) triangular filter banks, spaced using the mel scale to
the magnitude spectrum. Applying a discrete cosine transform to the log of the
filterbank outputs provides the final set of coefficients (for further details,
please refer to~\parencite{Lerch2012}). This representation
creates a perceptually relevant representation of spectral shape, in effect
mimicking the way in which humans might perceive the spectral shape of heart
sounds. The reasoning for this is that, as the aim is to provide a system with
performance better than, or equal to to that of a human, features that mimick
what a human percieves may prove effective at distinguishing conditions in the
way that a human does. This has shown to be effective in previous literature,
with multiple systems utilising perceptual features with
success~\parencite{Ortiz2016, Rubin2016, Quiceno-Manrique2010a}. 13 MFCCs were
calculated for each heart sound and averaged per sample to provide 13 features
per sample.\\
%TODO: Generate MFCC spectum

In addition to MFCCs, other statistical features were extracted from the
spectrum such as spread, skewness, kurtosis and flatness. These features aim to
provide alternate spectral measurements to MFCCs, in a similar way to their
temporal counterparts as described in Section~\ref{Time}.

Although the Fourier representation of PCG signals has proven effective in many
cases, there are drawbacks of this representation that must be considered. One
key issue that is inherent of fourier transforms is the time-frequency
tradeoff. An increase in frequency resolution will always result in a decrease
in temporal resolution. This poses a problem, as it is not possible to localize
transient events accurately in the frequency domain using this method. This
method may also suffer in the presence of background noise common in PCG
signals. Previous studies have shown that these factors may have a significant
impact when detecting conditions such as Coronary
Stenoses~\parencite{Ergen2001, Akay1990}

\subsubsection{Wavelet decomposition features}
The 
% TODO: Insert wavelet diagram here

\subsubsection{Scaling and Imputing}
particularly when using methods
that are sensitive to such as SVMs described in section

\subsection{Stacking Classifier with Cross-Validation}\label{class}
This meta-learning approach
has shown significantly success, with robust performance across a variety of classification
tasks~\parencite[p.498]{Tobergte2013a}.For this reason it was chosen
% TODO:Insert stacking classifier diagram

\subsection{Base Classifiers}

\subsubsection{SVM}

\subsubsection{Logistic Regression}

\subsubsection{Naive-Bayes}

% TODO: Replace this section
% \subsubsection{Signal quality classification}\label{Quality}

\subsection{Model Optimization}\label{optimise}

\subsubsection{Sequential Feature Selection}\label{SFS}
A wrapper method

\subsubsection{Particle Swarm Hyperparameter Optimisation}
Would ideally be placed inside feature selection


\subsection{Model Performance Metrics}\label{metrics}
% TODO: Insert cross validation diagram from data science handbook
Group cross-validation
$k$-fold cross validation

\section{Implementation}
This section details the implementation challenges posed by the experiment and describes how the project addresses them.
focus on using open source libraries throughout the project to avoid
`reinventing the wheel'. Integration of external libraries
Use of Python - quick development, wide variet of third party libraries to
allow for rapid prototyping

Interface
- Implementation of simple CLI for quick control of system parameters
- High computational cost - Multiprocessing, logging issues
Data Manipulation
- Pandas and Numpy for basic handeling and manipulation of data
- Splitting of data using sklearn
Implementation of features
- Joining of existing segmentation script and python code
- pyWavelets for wavelet features
- librosa for MFCCs
Implementation of machine learning classifiers
- Use of sklearn for base classifiers
- Addition of stacking classifier using mlxtend
- Saving of features and models to pickles, allowing for direct running of
intermediate section of system and for development and portability of generated models
Implementation of optimisatons
- Optunity for Hyperparameter optimization
- Mlxtend for SFS




\section{Evaluation}\label{Eval}
Weighted specificity and weighted Accuracy measures
Computational cost was not considered, unlike other entries to the physionet
challenge
\section{Further Work}\label{FurtherWork}
Handle silent sections of audio such as those highlighted by Goda et.\
al~\parencite{Goda2016}
% TODO: Consider talking about resampling using Homsi2016 method

\appendix
\section*{Appendices}
\addcontentsline{toc}{section}{Appendices}
\renewcommand{\thesubsection}{\Alph{subsection}}
\subsection{Table of Features}\label{appendixA}
\subsection{Commandline Interface}
\begin{lstlisting}[numbers=none]
usage: main.py [-h] [--features-fname OUTFNAME] [--segment] [--optimize]
               [--eval EVAL] [--select-features SELECT_FEATURES] [--backward]
               [--parameters_fname OUTFNAME] [--fs_fname OUTFNAME]
               [--no-parallel] [--reanalyse] [--verbose]
               [--resample-mix RESAMPLE_MIX] [--keep-logs]
               TESTDIR OUTDIR

Script for the classification of PCG data.

positional arguments:
  TESTDIR               Directory of test data to train the system
  OUTDIR                Directory to store output analyses

optional arguments:
  -h, --help            show this help message and exit
  --features-fname OUTFNAME, -o OUTFNAME
                        Specify the name of the file to save generated
                        features to for future use
  --segment             Run Matlab segmentation script to create segmentation
                        analysis
  --optimize            Run optimization algorithm to find best model and
                        parameters for classifier
  --eval EVAL, -e EVAL  Number of evaluation to pass to the particle swarm
                        optimization
  --select-features SELECT_FEATURES
                        Run feature selection algorithm to find best features
                        for model, either selecting or reducing features by
                        the integer specified. This depends on use of
                        --backward flag, to determine forward or backward
                        feature selection. (a value of 0 skips feature
                        selection entirely, using previously generated
                        features if available. A value less than 0 uses all
                        available features.)
  --backward, -b        Runs backward feature selection as opposed to default
                        forward selection.
  --parameters_fname OUTFNAME
                        Specify the name of the file to save generated
                        features to for future use
  --fs_fname OUTFNAME   Specify the name of the file to save generated feature
                        selection model to for future use
  --no-parallel, -p     Disable processing in parallel. (Will likely decrease
                        performance but may aid in debugging)
  --reanalyse           Force regeneration of database features
  --verbose, -v         Specifies level of verbosity in output. For example:
                        '-vvvvv' will output all information. '-v' will output
                        minimal information.
  --resample-mix RESAMPLE_MIX, -r RESAMPLE_MIX
                        Mix between bootstrap and jacknife resampling used to
                        balance the dataset (0=just jacknife, 1=just bootsrap)
  --keep-logs           Keep previously generated logs that aren't overwritten
                        by current process
\end{lstlisting}


\pagebreak{}
\printbibliography{}

\end{document}
