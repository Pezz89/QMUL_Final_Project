\documentclass[titlepage, 12pt]{scrartcl} \usepackage{enumitem}
\usepackage[british]{babel}
\usepackage[style=apa, backend=biber]{biblatex}
\DeclareLanguageMapping{british}{british-apa}
\usepackage{url}
\usepackage{float}
\usepackage{caption}
%\restylefloat{table}
\usepackage[table]{xcolor}
\usepackage{multirow}
\usepackage{perpage}
\MakePerPage{footnote}
\usepackage{abstract}
\usepackage{graphicx}
\usepackage{setspace}
% Create hyperlinks in bibliography
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{tabulary}

\usepackage[pass]{geometry}
\usepackage{pdflscape}
\usepackage{graphicx}

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{blindtext}
\setkomafont{disposition}{\normalfont\bfseries}

\usepackage{etoolbox}
\graphicspath{{./resources/}}
\addbibresource{~/Documents/library.bib}

%\newsavebox{\abstractbox}
%\renewenvironment{abstract}
%  {\begin{lrbox}{0}\begin{minipage}{\textwidth}
%   \begin{center}\normalfont\sectfont\abstractname\end{center}\quotation}
%  {\endquotation\end{minipage}\end{lrbox}%
%   \global\setbox\abstractbox=\box0 }

%\makeatletter
%\expandafter\patchcmd\csname\string\maketitle\endcsname
%  {\vskip\z@\@plus3fill}
%  {\vskip\z@\@plus2fill\box\abstractbox\vskip\z@\@plus1fill}
%  {}{}
%\makeatother

\newcommand{\dtoprule}{\specialrule{1pt}{0pt}{1.4pt}%
            \specialrule{1pt}{0pt}{\belowrulesep}%
            }
\newcommand{\dbottomrule}{\specialrule{1pt}{0pt}{1.4pt}%
            \specialrule{1pt}{0pt}{\belowrulesep}%
            }

\DeclareCiteCommand{\citeyearpar}
    {}
    {\mkbibparens{\bibhyperref{\printdate}}}
    {\multicitedelim}
    {}

% MATLAB Code block stuff...
\usepackage{color}
\usepackage{listings}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}

\lstset{language=Matlab,
   keywords={break,case,catch,continue,else,elseif,end,for,function,
      global,if,otherwise,persistent,return,switch,try,while},
   basicstyle=\ttfamily,
   keywordstyle=\color{blue},
   commentstyle=\color{gray},
   stringstyle=\color{dkgreen},
   numbers=left,
   numberstyle=\tiny\color{gray},
   stepnumber=1,
   numbersep=10pt,
   backgroundcolor=\color{white},
   tabsize=4,
   showspaces=false,
   showstringspaces=false}
\usepackage[shortcuts]{extdash}

\begin{document}
\newgeometry{lmargin=1.5cm}
\begin{titlepage}

    \begingroup

    \setlength{\tabcolsep}{1.5cm}

    \begin{tabular}[c]{p{0.30\textwidth} | p{0.4\textwidth}}

    {\vspace{1.2cm} \Large School of Electronic Engineering and Computer Science \par}
    &
    {\vspace{1.2cm} \large Sound and Music Computing \newline Project Report \the\year \par}\\

    & {\vspace{0.5cm} \Large \textbf{Extraction of Statistical Features from PCG Signals for the
Classification of Heart Abnormalities} \par}\\

    \vspace{0.4\textheight}
    \includegraphics[width=5cm]{qmul_logo}
    &
    {\vspace{1cm} \large \textbf{Samuel Perry}}\\

    &
    \multicolumn{1}{|r}{August \the\year}

    \end{tabular}

    \endgroup

\end{titlepage}
\restoregeometry

\doublespacing
\begin{abstract}
   Things and stuff and words...
\end{abstract}

\renewcommand{\abstractname}{Acknowledgements}
\begin{abstract}
I'd like to thanks anyone and everyone...
\end{abstract}

\tableofcontents
\newpage

\section{Introduction}
% TODO: Write brief overview of history of PCG signal analysis
% TODO: Explain fundamental heart sounds

\section{Related Work}
There are currently a wide variety of methods employed for the analysis and
classification of PCG signals. Current methods can typically be divided into 3
areas, each of which are combined to create full classification system. These
areas are: signal preprocessing, signal segmentation, and feature
extraction/classification. The performance and evaluation of complete systems
are also discussed in section~\ref{Classification}
% TODO: Make flow diagram of 3 stages


\subsection{Signal Preprocessing}
There are a large number of factors that lead to variation in quality of PCG
recordings: stethoscope type, make and model, its microphone/sensors, the
position used to record (i.e.\ lower left sternal border, apex, pulmonic area,
aortic area), built in filters/signal processing used by the stethoscope (i.e.\
noise filters, anti-tremor filters), medication that a patient may be taking,
as well as many other factors that may influence the recorded
signal~\parencite[p.4]{Pavlopoulos2004}. This presents a significant issue when
attempting to analyse and compare a dataset of signals, as variations in
recordings and artefacts caused by factors other than heart sounds will most
likely interfere with analysis and comparison methods. To account for this,
pre-processing methods are widely used, aiming to standardize a dataset. This
is also used as a way to accentuate features of the data that are expected to
be relevant for classification.\\

A common method employed is the use of decimation and a static filter to remove
unwanted spectral content that is most likely noise~\parencite{Liang1997a,
Homsi2016, Springer2016, Gupta2007}. This helps reduce higher frequency noise
such as speech, microphone movement, breething and other interference caused
externally. Signals are commonly downsampled to around 1--4KHz, with
anti-aliasing filter specifications varying across the literature. Generally,
highpass chebychev or butterworth filters are favoured with cutoff frequencies
ranging from 400--750Hz.\\

In addition, many methods decompose the filtered signal using wavelet based
methods such as the discrete wavelet transform
(DWT)~\parencite{Liang1997a, Pavlopoulos2004}, continuous
wavelet transform (CWT)~\parencite{Langley2016} or wavelet
package decomposition (WPD)~\parencite{Liang1998}.
Wavelet transforms are popular as, unlike Fourier transforms, they are well
localized in both the time and frequency domain. This allows for the analysis
of PCG signals across multiple frequency bands whilst maintaining transient
temporal events in the resulting decomposition~\parencite[p.93]{Ari2008}.
This may be used for analysis of transient events such as murmurs, that may
consist of higher frequency components than normal heart sounds.

\subsection{Signal Segmentation}\label{Segmentation}
Algorithms for the segmentation of PCG data aim to  extract the structure of
the signal over time. This is a key stage in the analysis of PCG signals as the
structure and relationships between the fundamental heart sounds (FHSs) form
the basis for much of the further analysis performed on PCG data.\\

% TODO: insert segmented graph of PCG cycle

A number of methods exist for the extraction of FHSs. Traditional methods rely
on direct extraction of peaks from envelopes in the time domain to determine
the structure of a signal.  These methods perform various transformation in
order to accentuate the transient events with the intention of isolating
them.\\ 
Liang et.\ al propose a method using the popular Shannon energy
envelope, achieving good accuracy across 37 recordings of
children~\citeyearpar{Liang1997b}. The algorithm aims to segment the data by
first extracting the envelope, then applying adaptive rule based thresholds to
determine peaks corresponding to segmentation points. When comparing results to
hand annotated ground truth, the system achieves a reported accuracy score of
84\%. However, due to the small sample size, and potential lack of noise in the
dataset used, this may not translate to a larger dataset recorded in
sub-optimal conditions.\\
More recent methods use spectral representations to assist in the splitting of
the FHSs, in particular using wavelet decomposition. These methods tend to
perform more robustly on signals of varying conditions.\\
Building on previous work, Liang et.\ al present an improved method, using the
discrete wavelet transform to decompose and reconstruct the signal into 7
distinct frequency bands~\citeyearpar{Liang1997a}.  Applying a similar method
of envelope extraction and peak picking to each frequency band, the best
estimate of all frequency bands is then chosen as the final result. Criterion
for this choice is based on number of S1s and S2s detected, and the number of
artefacts discarded for each frequency band. This method achieved an improved
accuracy of 93\% accuracy across a larger dataset of 77 recordings. This
suggests that the algorithm is as robust if not more so than previous work by
Liang et\ al.\\
Vepa et.\ al proposed a wavelet decomposition based method that uses a
combination of simplicity and envelope features~\citeyearpar{Vepa2008}. This
approach attempts to improve robustness when analysing signals of varying
quality by using multiple complimentary features, allowing the method to base
decisions on a variety of statistical properties. Evaluating the algorithm on a
collection of 160 heart cycles from a variety of sources, a reported accuracy
of 84\% was achieved.\\

A variety of machine learning methods have been implemented with reasonable
success. Gupta et.\ al present a method that applies $k$-means clustering to
replace standard threshold based methods for determining peak classification in
a standard envelope based segmentation algorithm~\citeyearpar{Gupta2007}. This achieved a reported
accuracy of 90.29\%. Due to the envelope based method for feature extraction,
this method is still suceptible to noise and artefacts that occur within the
frequency bands of the heart sounds.\\

Sepehri et.\ al propose a method that combines neural networks with Power
Spectral Density (PSD) estimates~\citeyearpar{Sepehri2010}. This method
exploits the periodic nature of S1 and S2 heart sounds, combined with their
narrow frequency range, to train a neural network to separate these sounds from
other sounds and murmurs. This method achieves a reported 93.6\% accuracy on a
significantly larger database than other methods detailed.\\

Most significant success in segmentation algorithms has been observed through use
of probabilistic models such as Hidden Markov Models (HMMs). Early research
using these models by Ricke et.\ al utilized embedded HMMs to model the 4
states of the PCG and their transitions~\citeyearpar{Ricke2005}. MFCCs and
Shannon Energy are used as feature vectors for the models. Results of
98\% accuracy were reported, although this was tested on only a small database
of signals.\\
Gill et.\ al achieve similar results, most notably with specific consideration
for the duration of each state in the HMM~\citeyearpar{Gill2005}. This is
handled through the extraction of 6 duration features based primarily on peaks,
which are then used as feature vectors for the HMM. Results of 98.6\%
sensitivity, 96.9\% positive predictivity for S1 sounds and 98.3\% sensitivity,
96.5\% positive predictivity for S2 sounds were reported.
The issue of state duration is further addressed by Schmidt et.\ al through use
of a duration-dependent hidden Markov (DHMM)~\citeyearpar{Schmidt2015}. The
DHMM is a modified HMM that considers the duration of the current state when
calculating the probability of transition to another state. This modification
scored a reported sensitivity of 98.8\% and a positive predictivity of
98.6\%.\\
Building on previous work using HMMs, Springer et.\ al presents a segmentation
algorithm by using hidden semi-markov models (HSMMs) in combination with
logistic regression~\citeyearpar{Springer2016}. Use of Hidden semi markov model
allows for a priori information on the duration of the current state to be used
in probability calculation of the subsequent state. In this case, the knowlege
that there is an upper and lower limit on the duration of each component is
used in calculation of transition probabilities.  A modified viterbi algorithm
is then used to calculate the most likely set of transitions based on observed
features. Logistic regression is used to improve discrimination between state
features when compared to discriminatory methods used by previous work.
Performance was evaluated on a significantly larger database than previous
methods and achieved a reported accuracy of $95.63\% \pm 0.85\%$. Due to it's
rigorous evaluation and high accuracy, this method is currently considered the
state-of-the-art for PCG signal segmentation.\\

Table~\ref{SegmentationTable} provides a brief overview of significant research
into PCG segmentation. For a more complete summary of the current state of PCG
segmentation, please refer to Liu et.\ al~\citeyearpar{Liu2016}

\newgeometry{margin=1cm} % modify this if you need even more space
\begin{landscape}
\begin{table}[htbp]
    \captionof{table}{Summary of Segmentation Algorithms} \label{SegmentationTable}
\scriptsize
%\centering
\rowcolors{1}{gray!15}{white}
\doublespacing
\begin{tabulary}{\linewidth}{LLLLL}
\dtoprule
Author                 & Method                                                                                         & Datasets                                                                                       & \mbox{Reported} Results         & Notes                                                                                            \\ \bottomrule
Springer et.\ al \citeyearpar{Springer2016} & HSMM, Logistic regression                                                                       & 10,172s of recordings from 112 patients. 12,181 first and 11,627 second heart sounds. & $95.63\pm0.85\%$                             & Supervised algorithm.                                                                                                                                                            \\
Huiying et.\ al \citeyearpar{Liang1997b} & Normalised average Shannon energy envelope, peak picking                                        & 37 recordings, 14 pathological murmurs and 23 physiological murmurs. 515 cycles       & $91.03\%\;Ac$                                          & Unsupervised Algorithm.  Dataset consists entirely of child recording. Optimized on full dataset                                                                                 \\
Vepa et.\ al \citeyearpar{Vepa2008}     & Wavelet decomposition, energy and simplicity measurement                                       & 160 heart cycles collected from a variety of sources (training CDs, web resources)    & $84\%\;Ac$                                             & Unsupervised Algorithm, Optimized on full dataset                                                                                                                                \\
Sun et.\ al \citeyearpar{Sun2014}             & Viola integral envelope extraction, short-time modified Hilbert transform, peak picking        & 6949s of recordings, from 121 patients                                                & $97.37\%\;Ac$                                          & Supervised algorithm. Tolerance for segmentation accuracy not specified                                                                                                          \\
Sepehri et.\ al \citeyearpar{Sepehri2010}        & Spectral density estimation, auto-regressive parameters, multi-layer perceptron neural network & 120 recording, from 60 patients                                                       & $93.6\%\;Ac$                                           & Supervised algorithm                                                                                                                                                             \\
Ricke et.\ al \citeyearpar{Ricke2005}    & Shannon energy (and related features), HMM                                                     & 9 recordings, from 9 patients                                                         & $98\%\;Ac$                                             & Supervised algorithm                                                                                                                                                             \\
Schmidt et.\ al \citeyearpar{Schmidt2015}  & DHMM, Auto-correlation duration features, Homomorphic envelogram                               & 113 recordings, from 113 patients. 8s per recording. 15 abnormal recordings           & $98.8\;Se,\;98.6\;P_+$ on test set                         & All data recorded ``lateral to the sternum in the fourth intercostal space on the left side''. Mix of noisy and clean recordings. 40 recording used for training, 73 for testing \\
Gill et.\ al \citeyearpar{Gill2005}         & Homomorphic envelogram, Embedded HMMs                                                          & 44 recording, 17 subjects. 30-60s per recording                                       & $98.6\%\;Ac, 96.9\;P_+$ for S1. $98.3\;Ac,\;96.5\;P_+$ for S2 & Recording taken in sub-optimal environments (noisy hospitals, offices etc...)                                                                                                    \\
Gupta et.\ al \citeyearpar{Gupta2007}    & Homomorphic filtering, $k$-means clustering                                                       & 41 patients, 340 heart cycles. 110 normal,  124 systolic murmur, 106 diastolic murmur & $90.29\%\;Ac$                                          & Unsupervised Algorithm.                                                                                                                                                          \\ \hline
\dbottomrule\\
% TODO: Add footnote explanation for Ac = Accuracy
% TODO: Add citeyearpar references to authors
\end{tabulary}
\end{table}
\end{landscape}
\restoregeometry


\doublespacing

\subsection{Feature extraction/Classification Models}\label{Classification}

A wide variety of methods exist for the extraction of statistical features and
classification of PCG data. Most notably, the recent Physionet/Computing in
Cardiology (CinC) Challenge 2016 has prompted the development of a range of methods
that have improved the quality of abnormality classification in noisy signals.
The challenge was assembled to provide researchers with a large database of PCG
signals of varying quality. This enabled the development of algorithms that
could be evaluated on a significant database, in order to determine performance
across a range of conditions/signal qualities~\parencite{Clifford2016}. This
section first details significant work produced prior to the challenge, and
then highlights key works produced for the challenge to outline the breadth of
methods for robust heart sound analysis.

\subsubsection{Work prior to the Physionet challenge}
Work prior to the Physionet challenge was conducted predominantly with the aim
of classifying specific heart conditions. Until recently, little research had
been produced with regards to general abnormality detection, with many projects
choosing to focus on specific conditions such as murmurs, atrial fibrillation
and flutter, and heart valve disease. This section outlines some key research
into these areas, alongside initial research into general abnormality
detection.\\

Reed et.\ al implement a simple general classification algorithm using artificial
neural networks (ANNs) and wavelet decomposition~\citeyearpar{Reed2004}. As
initial work into this field, preprocessing such as segmentation is not
performed and features remain relatively simple when compared to more recent
methods. Also, due to the comparitively small sample size used for training (1
patient per abnormality, 4 cycles per patient), a reported accuracy of 100\%
would likely generalise poorly. Thsi does however, serve as an early example of
limited success in general heart sound classification.\\

Maglogiannis et.\ al present a classifier for discrimination of heart valve
disease from regular heart sounds using an SVM (Support Vector Machine)
classifier~\citeyearpar{Maglogiannis2009}.  Roughly 100 features were extracted
from the signal, based on direct analysis of each heart cycle component (S1,
Systole, S2, Diastole) and the average shannon energy envelope of these
components.  A database of 198 heart sounds was curated for the project,
acquired from 8 sources, such as medical CDs and pre-existing databases.  An
accuracy of 91.43\% is reported using 10-fold stratified cross-validation.  In
addition, the project aimed to classify individual abnormalities in a 3 step
process, by distinguishing between systolic or diastolic murmurs, and then
distinguishing between aortic or mitral diseases. The classifier achieved
accuracy between 90-97\% for these classifications. This approach demonstrates
the potential for a system to accurately distinguish between normal and
abnormal heart sounds in a generalisable way, given carefully selected
features.\\

Ari et.\ al also propose an SVM based method for abnormality
classification~\citeyearpar{Ari2010}. A modified Least-squares SVM (LSSVM) is
used in order to improve separability between normal and abnormal datapoints
during training. 32 wavelet based features from previous literature are use as
feature vectors for a modified LSSVM, un-modified LSSVM and a standard SVM.
Comparison of the system shows that the proposed technique performs
significantly better on all test sets with an accuracy of between 86\% and
100\%, dependent on database. This research highlights the importance of
choosing an appropriate classification method for achieving accurate results.\\

Quiceno-Manrique et.\ al demonstrate the use of various time frequency
representations (TFR) such as short-time fourier transform, wavelet transforms,
Wigner-Ville distribution etc\ldots, with a $k$-nearest neighbour classifier
(k-NN) for systolic murmur detection~\citeyearpar{Quiceno-Manrique2010a}. This
work highlights the effectiveness of alternative TFRs to traditional fourier
methods. This method also employs Principle Component Analysis (PCA) for the
mapping of a high dimensional feature space to a lower dimension, for the
benefit of computational performance. Features were evaluated using a dataset
of of 22 patients, 6 of which were labeled as having a systolic murmur. The
highest reported accuracy was achieved using MFCCs as the primary feature
vector achieving a 98\% accuracy on 10-fold cross validation.\\

Schmidt et.\ al aim to find features that can be used for classification of
coronary artery disease through detection of small
murmurs~\citeyearpar{Schmidt2015}. A large number of features are then
calculated to provide vectors for classification. Parametric spectral features
such as ARMA are used, alongside instantaneous frequency and octave power
measurements. These are combined with complexity features such as sample
entropy and simplicity. Complexity features are chosen in an attempt to exploit
the likely stochastic nature of murmurs, when compared to normal heart sounds.
Given the large number of features calculated, PCA is used to retain only the
most relevant information. Quadratic discriminant analysis (QDA) is then used
as a classifier to provide a final accuracy score of 73\%.\\


\newgeometry{margin=1cm} % modify this if you need even more space
\begin{landscape}
\begin{table}[htbp]
    \captionof{table}{Summary of research prior to the Physionet Challenge 2016}\label{PriorWorkTable}
\scriptsize
%\centering
\rowcolors{1}{gray!15}{white}
\doublespacing
\begin{tabulary}{\linewidth}{LLLLLL}
\dtoprule
Author                   & Pre-processing/segmentation                                                                                                               & Features                                                                                                        & Classification Method & Dataset                                                                                                                 & Reported Accuracy                                  \\ \hline
Maglogiannis et.\ al     & Wavelet decomposition, Shannon energy peak picking                                                                                        & Features derived from wavelet decomposition and PCG segmentations                                               & SVM                   & 198 recordings, 38 normal, 41 AS systolic murmur, 43 MR systolic murmur, 38 AR diastolic murmur, 38 MS diastolic murmur & $91.43\%\;Ac$                                      \\
Ari et.\ al              & Amplitude envelope peak picking~\parencite{Ari2007}                                                                                       & Wavelet based features                                                                                          & LSSVM                 & 64 patients, 64 recordings, 512 cycles                                                                                  & $88.750-100\%\;Ac$ (dependant on abnormality type) \\
Quiceno-Manrique et.\ al & Downsampled to 4KHz, Normalised to maximum of signal, ECG assisted QRS complex detection algorithm used for segmentation                  & Spectral features derived from STFT, Wavelet decomposition and quadratic energy distributions                   & $k$-NN                & 22 patients, 16 normal, 6 abnormal, 8 recordings (12s) per patient                                                      & $98\%\;Ac$                                         \\
Schmidt et.\ al          & Signal filtered into frequency bands, Segmented by HMM based method+hand corrected, removal of high variance sub-segments to remove noise & Parametric spectral features (AR, ARMA and Music), Instantaneous frequency and amplitude, Power in octave bands & QDA                   & 435 Recordings, 133 patients, 70 normal, 63 abnormal                                                                    & $73\%\;Ac$                                         \\
Reed et.\ al             & ---                                                                                                                                       & Wavelet decomposition coefficients, Manual feature reduction                                                    & ANN                   & 5 patients, 4 cycles per patient                                                                                        & $100\%\;Ac$                                        \\
\dbottomrule\\
% TODO: Add footnote explanation for Ac = Accuracy
% TODO: Add citeyearpar references to authors
\end{tabulary}
\end{table}
\end{landscape}
\restoregeometry

\subsubsection{Physionet challenge entries}
\doublespacing
The 2016 Physionet/CinC Challenge aimed to encourage development of heart
abnormality detection algorithms by providing a large open database of PCG
signal recordings, sourced from a variety of both clinical and non-clinical
environments. (Further details on the provided database are provided in
section~\ref{Dataset} and it is described in full by Liu et.\
al~\citeyearpar{Liu2016}). In addition, participants were provided with a
state-of-the-art heart sound segmentation algorithm, as proposed by Springer
et.\ al in Section~\ref{Segmentation}. Participants were then tasked with the
creation of a classification algorithm that could robustly discriminate between
healthy and unhealthy heart sound samples. The challenge recieved 348 entries
in total, each of which was scored on a hidden test dataset
using a Modified accuracy measure ($MAcc$) as defined by Clifford et.
al~\citeyearpar{Clifford2016}:
\begin{table}[H]
\centering
\caption{Output Classification}
\label{OutputClassification}
\doublespacing
\begin{tabular}{llccc}
\hline
                              &                 & \multicolumn{3}{c}{Algorithm's Output}                                                    \\ \hline
                              &                 & \multicolumn{1}{l}{Normal} & \multicolumn{1}{l}{Uncertain} & \multicolumn{1}{l}{Abnormal} \\
\multirow{4}{*}{Ground Truth} & Normal, clean   & $Nn_1$                     & $Nq_1$                        & $Na_1$                       \\
                              & Normal, noisy   & $Nn_2$                     & $Nq_2$                        & $Na_2$                       \\
                              & Abnormal, clean & $An_1$                     & $Aq_1$                        & $Aa_1$                       \\
                              & Abnormal, noisy & $An_2$                     & $Aq_2$                        & $Aa_2$                       \\ \hline
\end{tabular}
\end{table}

\doublespacing

Weights are calculated as:
\begin{table}[H]
\centering
\doublespacing
\begin{tabular}{ll}
$Wa_1 = \frac{\text{Clean abnormal recordings}}{\text{Total abnormal recordings}}$ & $Wa_2 = \frac{\text{Noisy abnormal recordings}}{\text{Total abnormal recordings}}$ \\
$Wn_1 = \frac{\text{Clean normal recordings}}{\text{Total normal recordings}}$     & $Wn_2 = \frac{\text{Noisy normal recordings}}{\text{Total normal recordings}}$    
\end{tabular}
\end{table}

Modified sensitivity ($Se$), specificity ($Sp$) and overall accuracy ($MAcc$) are then calculated as:

\begin{align*}
    &Se=Wa_1\frac{Aa_1}{Aa_1+Aq_1+An_1}+Wa_2\frac{Aa_2+Aq_2}{Aa_2+Aq_2+An_2} \\
    &Sp=Wn_1\frac{Nn_1}{Na_1+Nq_1+Nn_1}+Wn_2\frac{Nn_2+Nq_2}{Na_2+Nq_2+Nn_2} \\
    &MAcc=\frac{Se+Sp}{2}
\end{align*}

This section summarises some of the key works presented for the challenge,
including the some of the most accurate models, and a baseline classifier
provided to participants as a starting point.\\

A simple baseline classifier was provided to participants, in order to
demonstrate the basic structure of systems expected for
entries~\parencite{Liu2016}. The classifier extracted a selection of 20 basic
features primarily focused on relative timings and amplitudes of heart sounds.
A binary logistic regression model is chosen for classification. From the 20
extracted features, 13 were selected based on their statistical significance
(measured using foreward liklihood ratio selection). The system achieved a
reported score of 66\% on the test set, giving a baseline score for challengers to build on.
In addition, the system was trained using leave-one-out cross validation. By
removing a single training database on each fold, the generalisation of the algorithm
trained on all other databases could then be evaluated. Results showed that
performance decreased significantly when training via this method, giving an
average accuracy of 59\%, with Training database $b$ scoring as low as 47\%.
This could suggest that individual databases in the dataset are not sufficiently
represented by other databases, or that features do not model abnormalities
sufficiently.\\

Homsi et.\ al proposed a system that utilised 131 time domain, STFT based and
wavelet based features, combined with nested ensemble classifiers to produce an
accuracy score of 84.48\%~\citeyearpar{Homsi2017}. Notably this algorithm
proposes the most features used for classification, combining many commonly
used features in previous PCG related literature such as wavelet decomposition
based features, MFCCs and Shannon Energy. The system also uses a total of 40
classifiers, 20 for signals labeled to be `standard' and 20 for thos labeled as
`atypical'. A mixture of Random Forrest, LogitBoost and Cost-Sensitive
Classifiers are used to classify signals in parallel. Final results are
combined using a rule based decision, designed through manual experimentation.\\
% TODO: Read into accuracy results for this method more closely

Potes et.\ al present a similar approach to that of Homsi et.\
al~\citeyearpar{Potes2016}. 124 similar time-frequency features are extracted
and used as vectors for an AdaBoost classifier. This was combined with a deep
learning approach using a Convolutional Neural Network (CNN) classifier. The
signal was decomposed into 4 frequency bands and segmented, to provide input to
the CNN. Results from both AdaBoost and CNN classifiers were then combined
using a set descision rule.  This method produced the highest score on the test
set for the challenge at 86.02\%.\\

- Ensemble of NNs, bootstrapping, range of features~\parencite{Zabihi2016}
- Classification through probability based methods~\parencite{Plesinger2017}
- Wavelet, MFCC and inter-beat neural network classifier~\parencite{Kay2017}
- Large number of features, tensor based feature reduction and
K-NN~\parencite{Bobillo2016}
- Convolutional neural networks, MFCCs~\parencite{Rubin2016}



\newgeometry{margin=1cm} % modify this if you need even more space
\begin{landscape}
\begin{table}[htbp]
    \captionof{table}{Summary of research prior to the Physionet Challenge 2016} \label{PriorWorkTable}
\scriptsize
%\centering
\rowcolors{1}{gray!15}{white}
\doublespacing
\begin{tabulary}{\linewidth}{LLLLL}
\dtoprule
Author                 & Method                                                                                         & Datasets                                                                                       & \mbox{Reported} Results         & Notes                                                                                            \\ \bottomrule
Springer et.\ al \citeyearpar{Springer2016} & HSMM, Logistic regression                                                                       & 10,172s of recordings from 112 patients. 12,181 first and 11,627 second heart sounds. & $95.63\pm0.85\%$                             & Supervised algorithm.                                                                                                                                                            \\
Huiying et.\ al \citeyearpar{Liang1997b} & Normalised average Shannon energy envelope, peak picking                                        & 37 recordings, 14 pathological murmurs and 23 physiological murmurs. 515 cycles       & $91.03\%\;Ac$                                          & Unsupervised Algorithm.  Dataset consists entirely of child recording. Optimized on full dataset                                                                                 \\
Vepa et.\ al \citeyearpar{Vepa2008}     & Wavelet decomposition, energy and simplicity measurement                                       & 160 heart cycles collected from a variety of sources (training CDs, web resources)    & $84\%\;Ac$                                             & Unsupervised Algorithm, Optimized on full dataset                                                                                                                                \\
Sun et.\ al \citeyearpar{Sun2014}             & Viola integral envelope extraction, short-time modified Hilbert transform, peak picking        & 6949s of recordings, from 121 patients                                                & $97.37\%\;Ac$                                          & Supervised algorithm. Tolerance for segmentation accuracy not specified                                                                                                          \\
Sepehri et.\ al \citeyearpar{Sepehri2010}        & Spectral density estimation, auto-regressive parameters, multi-layer perceptron neural network & 120 recording, from 60 patients                                                       & $93.6\%\;Ac$                                           & Supervised algorithm                                                                                                                                                             \\
Ricke et.\ al \citeyearpar{Ricke2005}    & Shannon energy (and related features), HMM                                                     & 9 recordings, from 9 patients                                                         & $98\%\;Ac$                                             & Supervised algorithm                                                                                                                                                             \\
Schmidt et.\ al \citeyearpar{Schmidt2015}  & DHMM, Auto-correlation duration features, Homomorphic envelogram                               & 113 recordings, from 113 patients. 8s per recording. 15 abnormal recordings           & $98.8\;Se,\;98.6\;P_+$ on test set                         & All data recorded ``lateral to the sternum in the fourth intercostal space on the left side''. Mix of noisy and clean recordings. 40 recording used for training, 73 for testing \\
Gill et.\ al \citeyearpar{Gill2005}         & Homomorphic envelogram, Embedded HMMs                                                          & 44 recording, 17 subjects. 30-60s per recording                                       & $98.6\%\;Ac, 96.9\;P_+$ for S1. $98.3\;Ac,\;96.5\;P_+$ for S2 & Recording taken in sub-optimal environments (noisy hospitals, offices etc...)                                                                                                    \\
Gupta et.\ al \citeyearpar{Gupta2007}    & Homomorphic filtering, $k$-means clustering                                                       & 41 patients, 340 heart cycles. 110 normal,  124 systolic murmur, 106 diastolic murmur & $90.29\%\;Ac$                                          & Unsupervised Algorithm.                                                                                                                                                          \\ \hline
\dbottomrule\\
% TODO: Add footnote explanation for Ac = Accuracy
% TODO: Add citeyearpar references to authors
\end{tabulary}
\end{table}
\end{landscape}
\restoregeometry

% TODO: Insert table of previous research methods, datasets and results

\section{Dataset}\label{Dataset}

\section{Design}
The system aims to provide robust heart abnormality detection for PCG signals,
such that use of the system could reliably recommend further medical attention
when neccesary.
\subsection{Signal Segmentation}
Choice of springer algorithm allows for direct comparison with Physionet
entries
\subsection{Choice of features}

Augmentation of features using 2nd order polynomial features
- Dangers of overfitting with higher order features
\subsubsection{Wavelet Decomposition}
% TODO: Insert wavelet diagram here
\subsection{Feature selection method}
PCA/KPCA
Sequential forward feature selection
\subsection{Classification Model Selection/Optimization}
Particle Swarm Optimization
Individual model structures used in optimization

\section{Implementation}
\section{Evaluation}
Group cross-validation
Weighted specificity and weighted Accuracy measures
Computational cost was not considered, unlike other entries to the physionet
challenge
Comparison with T-Pot
\section{Conclusion}



\pagebreak{}
\printbibliography{}

\end{document}
